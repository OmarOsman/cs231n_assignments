{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "softmax_google_colab_cs321n.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-title"
        ],
        "id": "E-IFfxQSWti_",
        "colab_type": "text"
      },
      "source": [
        "# Softmax exercise\n",
        "\n",
        "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
        "\n",
        "This exercise is analogous to the SVM exercise. You will:\n",
        "\n",
        "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
        "- implement the fully-vectorized expression for its **analytic gradient**\n",
        "- **check your implementation** with numerical gradient\n",
        "- use a validation set to **tune the learning rate and regularization** strength\n",
        "- **optimize** the loss function with **SGD**\n",
        "- **visualize** the final learned weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtZWsIeQwAAB",
        "colab_type": "code",
        "outputId": "f225c6af-8e05-423b-d846-3771ce24526b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assignment1  sample_data  spring1819_assignment1.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkq2dSJlW29Q",
        "colab_type": "code",
        "outputId": "48301d08-5fa4-4090-93e0-10bcf42b3178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd assignment1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/assignment1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LleU8dX1CqMT",
        "colab_type": "code",
        "outputId": "1f37657f-b990-4c26-865a-b53034c7d0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls cs231n\t\t      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifiers  data_utils.py  gradient_check.py  __pycache__\n",
            "datasets     features.py    __init__.py        vis_utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "RBxTGwoFWtjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from cs231n.data_utils import load_CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "WDjBYHKJWtjG",
        "colab_type": "code",
        "outputId": "c875120d-1586-45fb-bf93-d63791de5bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for the linear classifier. These are the same steps as we used for the\n",
        "    SVM, but condensed to a single function.  \n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = '/content/assignment1/cs231n/datasets/cifar-10-batches-py'\n",
        "    \n",
        "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
        "    try:\n",
        "       del X_train, y_train\n",
        "       del X_test, y_test\n",
        "       print('Clear previously loaded data.')\n",
        "    except:\n",
        "       pass\n",
        "\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "    \n",
        "    # subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "    X_dev = X_train[mask]\n",
        "    y_dev = y_train[mask]\n",
        "    \n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "    \n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "    X_dev -= mean_image\n",
        "    \n",
        "    # add bias dimension and transform into columns\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)\n",
        "print('dev labels shape: ', y_dev.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape:  (49000, 3073)\n",
            "Train labels shape:  (49000,)\n",
            "Validation data shape:  (1000, 3073)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (1000, 3073)\n",
            "Test labels shape:  (1000,)\n",
            "dev data shape:  (500, 3073)\n",
            "dev labels shape:  (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQoOcRa6WtjI",
        "colab_type": "text"
      },
      "source": [
        "## Softmax Classifier\n",
        "\n",
        "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZwLRS0WXZ1Q",
        "colab_type": "code",
        "outputId": "51991d1d-0512-47de-e91e-6d46ebfeb1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile /content/assignment1/cs231n/classifiers/softmax.py\n",
        "from builtins import range\n",
        "import numpy as np\n",
        "import pdb\n",
        "from random import shuffle\n",
        "from past.builtins import xrange\n",
        "\n",
        "def softmax_loss_naive(W, X, y, reg):\n",
        "    \"\"\"\n",
        "    Softmax loss function, naive implementation (with loops)\n",
        "\n",
        "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "    of N examples.\n",
        "\n",
        "    Inputs:\n",
        "    - W: A numpy array of shape (D, C) containing weights.\n",
        "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "      that X[i] has label c, where 0 <= c < C.\n",
        "    - reg: (float) regularization strength\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - loss as single float\n",
        "    - gradient with respect to weights W; an array of same shape as W\n",
        "    \"\"\"\n",
        "    # Initialize the loss and gradient to zero.\n",
        "    loss = 0.0\n",
        "    dW = np.zeros_like(W)\n",
        "\n",
        "    #############################################################################\n",
        "    # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
        "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "    # regularization!                                                           #\n",
        "    #############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
        "\n",
        "    # compute the loss and the gradient\n",
        "    num_classes = W.shape[1]\n",
        "    num_train = X.shape[0]\n",
        "    loss = 0.0\n",
        "    for i in range(num_train):\n",
        "        scores = np.exp(X[i].dot(W))\n",
        "        correct_class_score = scores[y[i]]\n",
        "        sum_exp = np.sum(scores)\n",
        "        loss += -np.log(correct_class_score/sum_exp)\n",
        "        \n",
        "        for j in range(num_classes):\n",
        "            dW[:,j] += (X[i] * scores[j]) / sum_exp  \n",
        "        dW[:,y[i]] -= X[i] \n",
        "          \n",
        "\n",
        "    # Right now the loss is a sum over all training examples, but we want it\n",
        "    # to be an average instead so we divide by num_train.\n",
        "    loss /= num_train\n",
        "    dW /= num_train\n",
        "\n",
        "    # Add regularization to the loss.\n",
        "    loss += reg * np.sum(W * W)\n",
        "    dW += 2 * reg * W\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    return loss, dW\n",
        "\n",
        "\n",
        "def softmax_loss_vectorized(W, X, y, reg):\n",
        "    \"\"\"\n",
        "    Softmax loss function, vectorized version.\n",
        "\n",
        "    Inputs and outputs are the same as softmax_loss_naive.\n",
        "    \"\"\"\n",
        "    # Initialize the loss and gradient to zero.\n",
        "    loss = 0.0\n",
        "    dW = np.zeros_like(W)\n",
        "    num_train = X.shape[0]\n",
        "    \n",
        "\n",
        "    #############################################################################\n",
        "    # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
        "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "    # regularization!                                                           #\n",
        "    #############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    \n",
        "    \n",
        "    scores = np.dot(X,W)\n",
        "    scores_exp = np.exp(scores)\n",
        "    \n",
        "        \n",
        "    correct_class_score = scores[range(num_train), y].reshape(-1,1)\n",
        "    numerator = np.exp(correct_class_score)\n",
        "    denomerator = np.sum(scores_exp,axis =1).reshape(-1,1)\n",
        "    \n",
        "    loss = np.sum(-np.log(numerator/denomerator))\n",
        "    loss/=num_train\n",
        "    loss += reg * np.sum(W * W)\n",
        "    \n",
        "    \n",
        "    #mask = np.zeros(scores.shape)\n",
        "    #mask = scores_exp / denomerator\n",
        "    #pdb.set_trace()\n",
        "    #mask[range(num_train), y] = (-(denomerator-numerator) / denomerator).squeeze(axis =1)\n",
        "    #dW = np.dot(X.T,mask)/num_train + 2*reg*W\n",
        "    \n",
        "    dev = scores_exp/np.sum(scores_exp,axis=1).reshape(-1,1)\n",
        "    dev[range(num_train), y] -= 1\n",
        "    dW = np.dot(X.T, dev)/ num_train + 2*reg*W \n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    return loss, dW"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/assignment1/cs231n/classifiers/softmax.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIoLDznDWtjJ",
        "colab_type": "code",
        "outputId": "cb8030ee-c435-4999-fc4e-2c782f8b875c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# First implement the naive softmax loss function with nested loops.\n",
        "# Open the file cs231n/classifiers/softmax.py and implement the\n",
        "# softmax_loss_naive function.\n",
        "\n",
        "from cs231n.classifiers.softmax import softmax_loss_naive\n",
        "import time\n",
        "\n",
        "# Generate a random softmax weight matrix and use it to compute the loss.\n",
        "W = np.random.randn(3073, 10) * 0.0001\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
        "print('loss: %f' % loss)\n",
        "print('sanity check: %f' % (-np.log(0.1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 2.358568\n",
            "sanity check: 2.302585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-inline"
        ],
        "id": "vKTxQuiCWtjL",
        "colab_type": "text"
      },
      "source": [
        "**Inline Question 1**\n",
        "\n",
        "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
        "\n",
        "$\\color{blue}{\\textit Your Answer:}$ *Fill this in* \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44DEtqG5WtjL",
        "colab_type": "code",
        "outputId": "3592603f-05b9-4452-fd58-07180a7bc6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
        "# version of the gradient that uses nested loops.\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
        "# The numeric gradient should be close to the analytic gradient.\n",
        "from cs231n.gradient_check import grad_check_sparse\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
        "\n",
        "# similar to SVM case, do another gradient check with regularization\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical: -3.738812 analytic: -3.738813, relative error: 1.509599e-08\n",
            "numerical: 0.123631 analytic: 0.123631, relative error: 2.308440e-07\n",
            "numerical: 0.180845 analytic: 0.180845, relative error: 1.729093e-07\n",
            "numerical: -0.061345 analytic: -0.061345, relative error: 4.203782e-07\n",
            "numerical: 0.862565 analytic: 0.862565, relative error: 3.539300e-08\n",
            "numerical: 1.287631 analytic: 1.287631, relative error: 3.776518e-08\n",
            "numerical: 1.262566 analytic: 1.262566, relative error: 4.048770e-08\n",
            "numerical: 1.335443 analytic: 1.335442, relative error: 4.907753e-08\n",
            "numerical: -1.173926 analytic: -1.173926, relative error: 5.535213e-08\n",
            "numerical: -0.772280 analytic: -0.772280, relative error: 8.998879e-08\n",
            "numerical: -0.976591 analytic: -0.976590, relative error: 7.397192e-09\n",
            "numerical: -0.541663 analytic: -0.541663, relative error: 2.025026e-08\n",
            "numerical: 0.307211 analytic: 0.307211, relative error: 1.610735e-07\n",
            "numerical: 2.273197 analytic: 2.273197, relative error: 3.805708e-08\n",
            "numerical: -1.301772 analytic: -1.301772, relative error: 1.988899e-08\n",
            "numerical: 1.774496 analytic: 1.774496, relative error: 3.517512e-08\n",
            "numerical: 0.614175 analytic: 0.614175, relative error: 1.204790e-07\n",
            "numerical: 0.738147 analytic: 0.738147, relative error: 6.191034e-08\n",
            "numerical: 0.878637 analytic: 0.878637, relative error: 1.903716e-08\n",
            "numerical: -0.503624 analytic: -0.503624, relative error: 1.587385e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4kE7IWPWtjO",
        "colab_type": "code",
        "outputId": "555cbe4e-19e6-40fa-81d1-eccb6086756b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
        "# implement a vectorized version in softmax_loss_vectorized.\n",
        "# The two versions should compute the same results, but the vectorized version should be\n",
        "# much faster.\n",
        "tic = time.time()\n",
        "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
        "\n",
        "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
        "tic = time.time()\n",
        "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
        "\n",
        "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
        "# of the gradient.\n",
        "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
        "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
        "print('Gradient difference: %f' % grad_difference)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive loss: 2.358568e+00 computed in 0.253458s\n",
            "vectorized loss: 2.358568e+00 computed in 0.013398s\n",
            "Loss difference: 0.000000\n",
            "Gradient difference: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "code"
        ],
        "id": "BNEPO96qWtjQ",
        "colab_type": "code",
        "outputId": "c36a3af4-bb33-4528-818f-3973bb8a0b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Use the validation set to tune hyperparameters (regularization strength and\n",
        "# learning rate). You should experiment with different ranges for the learning\n",
        "# rates and regularization strengths; if you are careful you should be able to\n",
        "# get a classification accuracy of over 0.35 on the validation set.\n",
        "from cs231n.classifiers import Softmax\n",
        "results = {}\n",
        "best_val = -1\n",
        "best_softmax = None\n",
        "learning_rates = [1e-7, 1e-8]\n",
        "regularization_strengths = [2.5e4, 2.7e4]\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Use the validation set to set the learning rate and regularization strength. #\n",
        "# This should be identical to the validation that you did for the SVM; save    #\n",
        "# the best trained softmax classifer in best_softmax.                          #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "for lr in learning_rates :\n",
        "  for reg in regularization_strengths : \n",
        "    softmax = Softmax()\n",
        "    loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg,\n",
        "                          num_iters=1500, verbose=True)\n",
        "    y_train_pred = softmax.predict(X_train)\n",
        "    train_accuracy = np.mean(y_train == y_train_pred)\n",
        "    \n",
        "    y_val_pred = softmax.predict(X_val)\n",
        "    val_accuracy = np.mean(y_val == y_val_pred)\n",
        "    if val_accuracy > best_val:\n",
        "      best_val = val_accuracy \n",
        "      best_softmax = softmax\n",
        "    \n",
        "    results[(lr, reg)] = (train_accuracy,val_accuracy)\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 / 1500: loss 775.823780\n",
            "iteration 100 / 1500: loss 284.538184\n",
            "iteration 200 / 1500: loss 105.436638\n",
            "iteration 300 / 1500: loss 39.926366\n",
            "iteration 400 / 1500: loss 15.950347\n",
            "iteration 500 / 1500: loss 7.125295\n",
            "iteration 600 / 1500: loss 3.972959\n",
            "iteration 700 / 1500: loss 2.776502\n",
            "iteration 800 / 1500: loss 2.330538\n",
            "iteration 900 / 1500: loss 2.290526\n",
            "iteration 1000 / 1500: loss 2.129427\n",
            "iteration 1100 / 1500: loss 2.058937\n",
            "iteration 1200 / 1500: loss 2.107633\n",
            "iteration 1300 / 1500: loss 2.104278\n",
            "iteration 1400 / 1500: loss 2.111052\n",
            "iteration 0 / 1500: loss 828.260151\n",
            "iteration 100 / 1500: loss 280.729970\n",
            "iteration 200 / 1500: loss 96.102777\n",
            "iteration 300 / 1500: loss 33.865610\n",
            "iteration 400 / 1500: loss 12.841666\n",
            "iteration 500 / 1500: loss 5.725127\n",
            "iteration 600 / 1500: loss 3.342375\n",
            "iteration 700 / 1500: loss 2.510698\n",
            "iteration 800 / 1500: loss 2.270299\n",
            "iteration 900 / 1500: loss 2.111297\n",
            "iteration 1000 / 1500: loss 2.112487\n",
            "iteration 1100 / 1500: loss 2.118271\n",
            "iteration 1200 / 1500: loss 2.065151\n",
            "iteration 1300 / 1500: loss 2.112563\n",
            "iteration 1400 / 1500: loss 2.094360\n",
            "iteration 0 / 1500: loss 769.724118\n",
            "iteration 100 / 1500: loss 695.993353\n",
            "iteration 200 / 1500: loss 629.677337\n",
            "iteration 300 / 1500: loss 569.576595\n",
            "iteration 400 / 1500: loss 514.925538\n",
            "iteration 500 / 1500: loss 466.084594\n",
            "iteration 600 / 1500: loss 421.270480\n",
            "iteration 700 / 1500: loss 381.312051\n",
            "iteration 800 / 1500: loss 344.983207\n",
            "iteration 900 / 1500: loss 312.572511\n",
            "iteration 1000 / 1500: loss 282.630571\n",
            "iteration 1100 / 1500: loss 255.786857\n",
            "iteration 1200 / 1500: loss 231.535120\n",
            "iteration 1300 / 1500: loss 209.562452\n",
            "iteration 1400 / 1500: loss 189.844755\n",
            "iteration 0 / 1500: loss 830.624492\n",
            "iteration 100 / 1500: loss 745.275713\n",
            "iteration 200 / 1500: loss 668.953200\n",
            "iteration 300 / 1500: loss 600.049201\n",
            "iteration 400 / 1500: loss 538.604497\n",
            "iteration 500 / 1500: loss 483.149554\n",
            "iteration 600 / 1500: loss 433.960115\n",
            "iteration 700 / 1500: loss 389.726697\n",
            "iteration 800 / 1500: loss 350.157348\n",
            "iteration 900 / 1500: loss 314.196030\n",
            "iteration 1000 / 1500: loss 282.159821\n",
            "iteration 1100 / 1500: loss 253.151780\n",
            "iteration 1200 / 1500: loss 227.519273\n",
            "iteration 1300 / 1500: loss 204.357895\n",
            "iteration 1400 / 1500: loss 183.590924\n",
            "lr 1.000000e-08 reg 2.500000e+04 train accuracy: 0.169163 val accuracy: 0.173000\n",
            "lr 1.000000e-08 reg 2.700000e+04 train accuracy: 0.182388 val accuracy: 0.183000\n",
            "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.331082 val accuracy: 0.342000\n",
            "lr 1.000000e-07 reg 2.700000e+04 train accuracy: 0.325245 val accuracy: 0.349000\n",
            "best validation accuracy achieved during cross-validation: 0.349000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HqurfXGWtjT",
        "colab_type": "code",
        "outputId": "395c3814-ef7f-4935-b94e-2333972b6a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate on test set\n",
        "# Evaluate the best softmax on test set\n",
        "y_test_pred = best_softmax.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax on raw pixels final test set accuracy: 0.335000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-inline"
        ],
        "id": "zAa3SP6XWtjW",
        "colab_type": "text"
      },
      "source": [
        "**Inline Question 2** - *True or False*\n",
        "\n",
        "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
        "\n",
        "$\\color{blue}{\\textit Your Answer:}$\n",
        "\n",
        "\n",
        "$\\color{blue}{\\textit Your Explanation:}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaWIuTHiWtjX",
        "colab_type": "code",
        "outputId": "15e2286d-4ba0-4dea-cc12-f3153d03e97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "# Visualize the learned weights for each class\n",
        "w = best_softmax.W[:-1,:] # strip out the bias\n",
        "w = w.reshape(32, 32, 3, 10)\n",
        "\n",
        "w_min, w_max = np.min(w), np.max(w)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    \n",
        "    # Rescale the weights to be between 0 and 255\n",
        "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
        "    plt.imshow(wimg.astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAF8CAYAAAAAZIWVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA1QQBEEQBMGT+G8uhFY6Kh0ITwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrwQCpUahkHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}